- llama基本上中文一个汉字对应两个token
- 1word_2byte_16bit_2token


- 近义词训练
	- 使用图谱的节点和标签关联数据来训练
	- 对比三个模型的效果
		- 项目原始的少量cnsd数据训练的 模型
		- 经过大量news训练后的模型
		- news训练后加入近义词有监督训练的模型