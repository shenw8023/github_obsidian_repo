
## 区分
-   按照并行方式来分：模型并行 vs 数据并行
-   按照更新方式来分：同步更新 vs 异步更新


## 数据并行
- 参考：
	- [通信原语图示](https://zhuanlan.zhihu.com/p/465967735)
	- [Parameter Server算法 vs. Ring AllReduce算法](https://blog.csdn.net/weixin_44966641/article/details/120248357)


### Ring AllReduce算法
- Parameter Service最大的问题就是通信成本和GPU的数量线性相关。而Ring AllReduce的通信成本与GPU数量无关。Ring AllReduce分为两个步骤：Scatter Reduce和All Gather。
- 通信成本：$T = 2(N-1)\frac{K}{N}$

- 通信架构
	- ![[Pasted image 20230524165245.png]]

- Reduce Scatter
	- 每张卡独立前向计算自己那部分数据，反向传播得到每个参数的梯度
	- 我们<mark style="background: #FF5582A6;">将参数分为N份（N张卡）</mark>
		- 例如：假设网络总参数量为8：  $[w_1, w_2, w_3...w_8]$
		- $A=[w_1,w_2]$     $B=[w_3, w_4]$    $C=[w_5, w_6]$   $D=[w_7, w_8]$
		
	- 相邻的GPU传递不同的参数，在传递N-1次之后，可以得到<mark style="background: #FF5582A6;">每一份参数</mark>的累积（在不同的GPU上）。
		- Reduce：将每张卡上计算得到的A组参数进行求和规约，BCD也类似
		- Scatter：将结果分发到不同的卡上，每张卡上分别存了<mark style="background: #FF5582A6;">一份参数</mark>（例如A组参数）的规约结果

	- ![[Pasted image 20230524154500.png]]
	- ![[Pasted image 20230524164257.png]]
	
- All Gather：
	- 得到<mark style="background: #FF5582A6;">每一份参数</mark>的累积之后，再做一次传递，同步到所有的GPU上。
	- [动图演示](https://img-blog.csdnimg.cn/468cdc6ef9944e57b90496e574e580d2.gif#pic_center)
	- 下图应该是All Gather, 普通的Gather只会gather到一个节点
	- ![[Pasted image 20230524164946.png]]