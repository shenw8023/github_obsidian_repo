- claude https://zhuanlan.zhihu.com/p/629225773 #TODO 
- OPT
	- Open Pre-trained Transformer Language Models
- Bloom
- 打标任务，我们的llama对候选标签的长度非常敏感
	- 怎么发现的：
		- 验证原来的测试数据还是能得到正确结果，说明模型本身没变
		- 测试多个样例，发现在新数据上，输出的无关标签”计算机视觉“
		- 我把5个这些无关标签添加到原来的测试数据的候选标签后面，测试原来数据后发现，模型会把这5个无关标签也输出
		- 我用这5个无关标签替换掉原来测试数据的候选标签的5项，测试后发现就不输出这5个无关标签了，说明是候选标签太多了，导致模型不会回答了，倾向于全部输出
		- 进一步实验确定模型对候选标签的数量很敏感
		- 可能原因：
			- sft阶段的候选标签数量比较固定，导致过拟合了，自然就对标签数量敏感


- 数据多样性和丰富性的策略
	- 去重 #TODO
	- 收集数据的主题类型，任务类型
		- 参考Apalca和Chinese-LLaMA-Alpaca中的crwal_prompt.py
		- topic_list = ["科技", "娱乐", "体育", "金融", "时政", "教育"...]
		- task_list = ["开放式生成", "分类", "问答", "编辑", "摘要", "写作", "翻译"]
	 - 每个类型随机抽几十条数据，大约一千条，使用p-tuning微调一个分类模型，每个类型下收集一批数据
	 - 然后每个类型下筛选高质量的数据
	 - 最后保证整体的数据均衡，再加入一些不属于任意类型的数据的采样，提高丰富度
 - 数据集
	 - 多轮对话
		 - lianjiaTech/BELLE
	 - 思维链数据
	 - GPT生成的
	 - 真实用户提交的：shareGPT
	 - 


- 业务数据准备
	- 使用GPT对一个文段做提问，生成多种问题 #TODO 
	- 复习一下Alpaca


